# create_work_memory_ollama.py
# ğŸ¯ åˆ›å»ºå·¥ä½œè®°å¿†çš„ç¤ºä¾‹ (Ollamaç‰ˆ)
import os

from dotenv import load_dotenv

from memos.memories.textual.item import TextualMemoryItem, TreeNodeTextualMemoryMetadata


def create_work_memory_ollama():
    """
    ğŸ¯ åˆ›å»ºå·¥ä½œè®°å¿†çš„ç¤ºä¾‹ (Ollamaç‰ˆ)
    """

    print("ğŸš€ å¼€å§‹åˆ›å»ºå·¥ä½œè®°å¿† (Ollamaç‰ˆ)...")

    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()

    # æ£€æŸ¥Ollamaé…ç½®
    ollama_base_url = os.getenv("OLLAMA_BASE_URL")
    ollama_chat_model = os.getenv("OLLAMA_CHAT_MODEL")
    ollama_embed_model = os.getenv("OLLAMA_EMBED_MODEL")

    if not ollama_base_url or not ollama_chat_model or not ollama_embed_model:
        raise ValueError(
            "âŒ æœªé…ç½®Ollamaç¯å¢ƒå˜é‡ã€‚è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®OLLAMA_BASE_URLã€OLLAMA_CHAT_MODELã€OLLAMA_EMBED_MODELã€‚"
        )

    print("âœ… æ£€æµ‹åˆ°Ollamaæœ¬åœ°æ¨¡å‹æ¨¡å¼")

    # è·å–ç”¨æˆ·ID
    user_id = os.getenv("MOS_USER_ID", "default_user")

    # åˆ›å»ºå·¥ä½œè®°å¿†çš„å…ƒæ•°æ®
    work_metadata = TreeNodeTextualMemoryMetadata(
        user_id=user_id,
        type="procedure",
        source="conversation",
        confidence=80.0,
        memory_type="WorkingMemory",  # å·¥ä½œè®°å¿†
        key="ä»Šæ—¥ä»»åŠ¡",
        tags=["ä»»åŠ¡", "ä»Šæ—¥"],
    )

    # åˆ›å»ºè®°å¿†é¡¹
    work_memory = TextualMemoryItem(
        memory="ä»Šå¤©éœ€è¦å®Œæˆä»£ç å®¡æŸ¥ã€å›¢é˜Ÿä¼šè®®ã€ä»¥åŠå‡†å¤‡æ˜å¤©çš„æ¼”ç¤º", metadata=work_metadata
    )

    print(f"å·¥ä½œè®°å¿†: {work_memory.memory}")
    print(f"è®°å¿†ç±»å‹: {work_memory.metadata.memory_type}")
    print("ğŸ¯ é…ç½®æ¨¡å¼: OLLAMA")
    print(f"ğŸ¤– èŠå¤©æ¨¡å‹: {ollama_chat_model}")
    print(f"ğŸ” åµŒå…¥æ¨¡å‹: {ollama_embed_model}")

    return work_memory


if __name__ == "__main__":
    create_work_memory_ollama()
