# create_project_memory_ollama.py
# ğŸ¯ åˆ›å»ºé¡¹ç›®è®°å¿†çš„ç¤ºä¾‹ (Ollamaç‰ˆ)
import os
from dotenv import load_dotenv
from memos.memories.textual.item import TextualMemoryItem, TreeNodeTextualMemoryMetadata

def create_project_memory_ollama():
    """
    ğŸ¯ åˆ›å»ºé¡¹ç›®è®°å¿†çš„ç¤ºä¾‹ (Ollamaç‰ˆ)
    """
    
    print("ğŸš€ å¼€å§‹åˆ›å»ºé¡¹ç›®è®°å¿† (Ollamaç‰ˆ)...")
    
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()
    
    # æ£€æŸ¥Ollamaé…ç½®
    ollama_base_url = os.getenv("OLLAMA_BASE_URL")
    ollama_chat_model = os.getenv("OLLAMA_CHAT_MODEL")
    ollama_embed_model = os.getenv("OLLAMA_EMBED_MODEL")
    
    if not ollama_base_url or not ollama_chat_model or not ollama_embed_model:
        raise ValueError("âŒ æœªé…ç½®Ollamaç¯å¢ƒå˜é‡ã€‚è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®OLLAMA_BASE_URLã€OLLAMA_CHAT_MODELã€OLLAMA_EMBED_MODELã€‚")
    
    print("âœ… æ£€æµ‹åˆ°Ollamaæœ¬åœ°æ¨¡å‹æ¨¡å¼")
    
    # è·å–ç”¨æˆ·ID
    user_id = os.getenv("MOS_USER_ID", "default_user")
    
    # åˆ›å»ºé¡¹ç›®è®°å¿†çš„å…ƒæ•°æ®
    project_metadata = TreeNodeTextualMemoryMetadata(
        user_id=user_id,
        type="fact",
        source="file",
        confidence=95.0,
        memory_type="LongTermMemory",
        key="AIé¡¹ç›®_è¯¦æƒ…",
        entities=["AIé¡¹ç›®", "æœºå™¨å­¦ä¹ "],
        tags=["é¡¹ç›®", "AI", "é‡è¦"],
        sources=["é¡¹ç›®æ–‡æ¡£", "ä¼šè®®è®°å½•"]
    )

    # åˆ›å»ºè®°å¿†é¡¹
    project_memory = TextualMemoryItem(
        memory="AIé¡¹ç›®æ˜¯ä¸€ä¸ªæ™ºèƒ½å®¢æœç³»ç»Ÿï¼Œä½¿ç”¨æœ€æ–°çš„NLPæŠ€æœ¯ï¼Œé¢„è®¡6ä¸ªæœˆå®Œæˆ",
        metadata=project_metadata
    )

    print(f"é¡¹ç›®è®°å¿†: {project_memory.memory}")
    print(f"æ¥æº: {project_memory.metadata.sources}")
    print(f"ğŸ¯ é…ç½®æ¨¡å¼: OLLAMA")
    print(f"ğŸ¤– èŠå¤©æ¨¡å‹: {ollama_chat_model}")
    print(f"ğŸ” åµŒå…¥æ¨¡å‹: {ollama_embed_model}")
    
    return project_memory

if __name__ == "__main__":
    create_project_memory_ollama() 