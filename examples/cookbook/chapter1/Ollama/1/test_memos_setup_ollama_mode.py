# test_memos_setup_ollama_mode.py
# ğŸ¯ Ollamaæ¨¡å¼éªŒè¯è„šæœ¬ - ä½¿ç”¨æœ¬åœ°Ollamaæ¨¡å‹å’Œæ‰‹åŠ¨é…ç½®
import os
import sys

from dotenv import load_dotenv


def check_ollama_environment():
    """ğŸ¯ æ£€æŸ¥Ollamaç¯å¢ƒå˜é‡é…ç½®"""
    print("ğŸ” æ£€æŸ¥Ollamaç¯å¢ƒå˜é‡é…ç½®...")

    # åŠ è½½.envæ–‡ä»¶
    load_dotenv()

    # æ£€æŸ¥Ollamaé…ç½®
    ollama_base_url = os.getenv("OLLAMA_BASE_URL")
    ollama_chat_model = os.getenv("OLLAMA_CHAT_MODEL")
    ollama_embed_model = os.getenv("OLLAMA_EMBED_MODEL")

    print("ğŸ“‹ Ollamaç¯å¢ƒå˜é‡çŠ¶æ€:")

    if ollama_base_url:
        print(f"  âœ… OLLAMA_BASE_URL: {ollama_base_url}")
        print(f"  âœ… OLLAMA_CHAT_MODEL: {ollama_chat_model or 'âŒ æœªé…ç½®'}")
        print(f"  âœ… OLLAMA_EMBED_MODEL: {ollama_embed_model or 'âŒ æœªé…ç½®'}")
        ollama_configured = bool(ollama_base_url and ollama_chat_model and ollama_embed_model)

        if ollama_configured:
            print("âœ… Ollamaé…ç½®å®Œæ•´")
        else:
            print("âŒ Ollamaé…ç½®ä¸å®Œæ•´")

        return ollama_configured
    else:
        print("  âŒ OLLAMA_BASE_URL: æœªé…ç½®")
        print("  âŒ OLLAMA_CHAT_MODEL: æœªé…ç½®")
        print("  âŒ OLLAMA_EMBED_MODEL: æœªé…ç½®")
        return False


def check_memos_installation():
    """ğŸ¯ æ£€æŸ¥MemOSå®‰è£…çŠ¶æ€"""
    print("\nğŸ” æ£€æŸ¥MemOSå®‰è£…çŠ¶æ€...")

    try:
        import memos

        print(f"âœ… MemOSç‰ˆæœ¬: {memos.__version__}")

        # æµ‹è¯•æ ¸å¿ƒç»„ä»¶å¯¼å…¥
        from memos.configs.mem_cube import GeneralMemCubeConfig
        from memos.configs.mem_os import MOSConfig
        from memos.mem_cube.general import GeneralMemCube
        from memos.mem_os.main import MOS

        print("âœ… æ ¸å¿ƒç»„ä»¶å¯¼å…¥æˆåŠŸ")
        return True

    except ImportError as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return False
    except Exception as e:
        print(f"âŒ å…¶ä»–é”™è¯¯: {e}")
        return False


def test_ollama_functionality():
    """ğŸ¯ æµ‹è¯•Ollamaæ¨¡å¼åŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•Ollamaæ¨¡å¼åŠŸèƒ½...")

    try:
        from memos.configs.mem_cube import GeneralMemCubeConfig
        from memos.configs.mem_os import MOSConfig
        from memos.mem_cube.general import GeneralMemCube
        from memos.mem_os.main import MOS

        # è·å–ç¯å¢ƒå˜é‡
        ollama_base_url = os.getenv("OLLAMA_BASE_URL")
        ollama_chat_model = os.getenv("OLLAMA_CHAT_MODEL")
        ollama_embed_model = os.getenv("OLLAMA_EMBED_MODEL")

        print("ğŸš€ åˆ›å»ºOllamaé…ç½®...")

        # åˆ›å»ºMOSé…ç½®
        mos_config = MOSConfig(
            user_id=os.getenv("MOS_USER_ID", "default_user"),
            chat_model={
                "backend": "ollama",
                "config": {
                    "model_name_or_path": ollama_chat_model,
                    "api_base": ollama_base_url,
                    "temperature": 0.7,
                    "max_tokens": 1024,
                },
            },
            mem_reader={
                "backend": "simple_struct",
                "config": {
                    "llm": {
                        "backend": "ollama",
                        "config": {
                            "model_name_or_path": ollama_chat_model,
                            "api_base": ollama_base_url,
                        },
                    },
                    "embedder": {
                        "backend": "ollama",
                        "config": {
                            "model_name_or_path": ollama_embed_model,
                            "api_base": ollama_base_url,
                        },
                    },
                    "chunker": {
                        "backend": "sentence",
                        "config": {
                            "tokenizer_or_token_counter": "gpt2",
                            "chunk_size": 512,
                            "chunk_overlap": 128,
                            "min_sentences_per_chunk": 1,
                        },
                    },
                },
            },
            enable_textual_memory=True,
            top_k=int(os.getenv("MOS_TOP_K", "5")),
        )

        # åˆ›å»ºMemCubeé…ç½®
        cube_config = GeneralMemCubeConfig(
            user_id=os.getenv("MOS_USER_ID", "default_user"),
            cube_id=f"{os.getenv('MOS_USER_ID', 'default_user')}_cube",
            text_mem={
                "backend": "general_text",
                "config": {
                    "extractor_llm": {
                        "backend": "ollama",
                        "config": {
                            "model_name_or_path": ollama_chat_model,
                            "api_base": ollama_base_url,
                        },
                    },
                    "embedder": {
                        "backend": "ollama",
                        "config": {
                            "model_name_or_path": ollama_embed_model,
                            "api_base": ollama_base_url,
                        },
                    },
                    "vector_db": {
                        "backend": "qdrant",
                        "config": {
                            "collection_name": f"{os.getenv('MOS_USER_ID', 'default_user')}_collection",
                            "vector_dimension": 768,  # nomic-embed-textçš„ç»´åº¦
                            "distance_metric": "cosine",
                        },
                    },
                },
            },
            act_mem={"backend": "uninitialized"},
            para_mem={"backend": "uninitialized"},
        )

        print("âœ… é…ç½®åˆ›å»ºæˆåŠŸï¼")

        # åˆ›å»ºMOSå®ä¾‹å’ŒMemCube
        print("ğŸš€ åˆ›å»ºMOSå®ä¾‹å’ŒMemCube...")
        memory = MOS(mos_config)
        mem_cube = GeneralMemCube(cube_config)
        memory.register_mem_cube(mem_cube)

        print("âœ… MOSå®ä¾‹å’ŒMemCubeåˆ›å»ºæˆåŠŸï¼")
        print(f"  ğŸ“Š ç”¨æˆ·ID: {memory.user_id}")
        print(f"  ğŸ“Š ä¼šè¯ID: {memory.session_id}")
        print(f"  ğŸ“Š MemCube ID: {mem_cube.config.cube_id}")

        # æµ‹è¯•æ·»åŠ è®°å¿†
        print("\nğŸ§  æµ‹è¯•æ·»åŠ è®°å¿†...")
        memory.add(memory_content="è¿™æ˜¯ä¸€ä¸ªOllamaæ¨¡å¼çš„æµ‹è¯•è®°å¿†")
        print("âœ… è®°å¿†æ·»åŠ æˆåŠŸï¼")

        # æµ‹è¯•èŠå¤©åŠŸèƒ½
        print("\nğŸ’¬ æµ‹è¯•èŠå¤©åŠŸèƒ½...")
        response = memory.chat("æˆ‘åˆšæ‰æ·»åŠ äº†ä»€ä¹ˆè®°å¿†ï¼Ÿ")
        print(f"âœ… èŠå¤©å“åº”: {response}")

        # æµ‹è¯•æœç´¢åŠŸèƒ½
        print("\nğŸ” æµ‹è¯•æœç´¢åŠŸèƒ½...")
        search_results = memory.search("æµ‹è¯•è®°å¿†", top_k=3)
        if search_results and search_results.get("text_mem"):
            print(f"âœ… æœç´¢æˆåŠŸï¼Œæ‰¾åˆ° {len(search_results['text_mem'])} ä¸ªç»“æœ")
        else:
            print("âš ï¸ æœç´¢æœªè¿”å›ç»“æœ")

        # æµ‹è¯•MemCubeç›´æ¥æ“ä½œ
        print("\nğŸ”§ æµ‹è¯•MemCubeç›´æ¥æ“ä½œ...")
        mem_cube.text_mem.add(
            [
                {
                    "memory": "è¿™æ˜¯é€šè¿‡MemCubeç›´æ¥æ·»åŠ çš„è®°å¿†",
                    "metadata": {"source": "conversation", "type": "fact", "confidence": 0.9},
                }
            ]
        )
        print("âœ… MemCubeç›´æ¥æ“ä½œæˆåŠŸï¼")

        print("âœ… Ollamaæ¨¡å¼åŠŸèƒ½æµ‹è¯•æˆåŠŸï¼")
        return True

    except Exception as e:
        print(f"âŒ Ollamaæ¨¡å¼åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        print("ğŸ’¡ æç¤ºï¼šè¯·æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦è¿è¡Œï¼Œæ¨¡å‹æ˜¯å¦å·²ä¸‹è½½ã€‚")
        return False


def main():
    """ğŸ¯ Ollamaæ¨¡å¼ä¸»éªŒè¯æµç¨‹"""
    print("ğŸš€ å¼€å§‹MemOS Ollamaæ¨¡å¼ç¯å¢ƒéªŒè¯...\n")

    # æ­¥éª¤1: æ£€æŸ¥Ollamaç¯å¢ƒå˜é‡
    env_ok = check_ollama_environment()

    # æ­¥éª¤2: æ£€æŸ¥å®‰è£…çŠ¶æ€
    install_ok = check_memos_installation()

    # æ­¥éª¤3: æµ‹è¯•åŠŸèƒ½
    if env_ok and install_ok:
        func_ok = test_ollama_functionality()
    else:
        func_ok = False
        if not env_ok:
            print("\nâš ï¸ ç”±äºOllamaç¯å¢ƒå˜é‡é…ç½®ä¸å®Œæ•´ï¼Œè·³è¿‡åŠŸèƒ½æµ‹è¯•")
        elif not install_ok:
            print("\nâš ï¸ ç”±äºMemOSå®‰è£…å¤±è´¥ï¼Œè·³è¿‡åŠŸèƒ½æµ‹è¯•")

    # æ€»ç»“
    print("\n" + "=" * 50)
    print("ğŸ“Š Ollamaæ¨¡å¼éªŒè¯ç»“æœæ€»ç»“:")
    print(f"  Ollamaç¯å¢ƒå˜é‡: {'âœ… é€šè¿‡' if env_ok else 'âŒ å¤±è´¥'}")
    print(f"  MemOSå®‰è£…: {'âœ… é€šè¿‡' if install_ok else 'âŒ å¤±è´¥'}")
    print(f"  åŠŸèƒ½æµ‹è¯•: {'âœ… é€šè¿‡' if func_ok else 'âŒ å¤±è´¥'}")

    if env_ok and install_ok and func_ok:
        print("\nğŸ‰ æ­å–œï¼MemOS Ollamaæ¨¡å¼ç¯å¢ƒé…ç½®å®Œå…¨æˆåŠŸï¼")
        print("ğŸ’¡ ä½ ç°åœ¨å¯ä»¥å¼€å§‹ä½¿ç”¨MemOS Ollamaæ¨¡å¼äº†ã€‚")
        print("ğŸ’¡ ä½¿ç”¨æ–¹å¼: æ‰‹åŠ¨é…ç½®MOSConfigå’ŒGeneralMemCubeConfig")
    elif install_ok and env_ok:
        print("\nâš ï¸ MemOSå·²å®‰è£…ï¼ŒOllamaå·²é…ç½®ï¼Œä½†åŠŸèƒ½æµ‹è¯•å¤±è´¥ã€‚")
        print("ğŸ’¡ è¯·æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦è¿è¡Œï¼Œæ¨¡å‹æ˜¯å¦å·²ä¸‹è½½ã€‚")
    elif install_ok:
        print("\nâš ï¸ MemOSå·²å®‰è£…ï¼Œä½†éœ€è¦é…ç½®Ollamaç¯å¢ƒå˜é‡æ‰èƒ½æ­£å¸¸ä½¿ç”¨ã€‚")
        print("ğŸ’¡ è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®OLLAMA_BASE_URLã€OLLAMA_CHAT_MODELã€OLLAMA_EMBED_MODELã€‚")
    else:
        print("\nâŒ ç¯å¢ƒé…ç½®å­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯ã€‚")

    return bool(env_ok and install_ok and func_ok)


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
