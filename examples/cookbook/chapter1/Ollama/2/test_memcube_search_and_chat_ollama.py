# test_memcube_search_and_chat_ollama.py
# ğŸ¯ æµ‹è¯•MemCubeçš„æœç´¢å’Œå¯¹è¯åŠŸèƒ½ (Ollamaç‰ˆ)
import os
from dotenv import load_dotenv
from memos.configs.mem_os import MOSConfig
from memos.mem_os.main import MOS

def create_mos_config():
    """
    ğŸ¯ åˆ›å»ºMOSé…ç½® (Ollamaç‰ˆ)
    """
    load_dotenv()
    
    user_id = os.getenv("MOS_USER_ID", "default_user")
    top_k = int(os.getenv("MOS_TOP_K", "5"))
    ollama_base_url = os.getenv("OLLAMA_BASE_URL")
    ollama_chat_model = os.getenv("OLLAMA_CHAT_MODEL")
    ollama_embed_model = os.getenv("OLLAMA_EMBED_MODEL")
    
    if not ollama_base_url or not ollama_chat_model or not ollama_embed_model:
        raise ValueError("âŒ æœªé…ç½®Ollamaç¯å¢ƒå˜é‡ã€‚è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®OLLAMA_BASE_URLã€OLLAMA_CHAT_MODELã€OLLAMA_EMBED_MODELã€‚")
    
    # Ollamaæ¨¡å¼é…ç½®
    return MOSConfig(
        user_id=user_id,
        chat_model={
            "backend": "ollama",
            "config": {
                "model_name_or_path": ollama_chat_model,
                "api_base": ollama_base_url,
                "temperature": 0.1,
                "max_tokens": 1024,
            }
        },
        mem_reader={
            "backend": "simple_struct",
            "config": {
                "llm": {
                    "backend": "ollama",
                    "config": {
                        "model_name_or_path": ollama_chat_model,
                        "api_base": ollama_base_url,
                    }
                },
                "embedder": {
                    "backend": "ollama",
                    "config": {
                        "model_name_or_path": ollama_embed_model,
                        "api_base": ollama_base_url,
                    }
                },
                "chunker": {
                    "backend": "sentence",
                    "config": {
                        "tokenizer_or_token_counter": "gpt2",
                        "chunk_size": 512,
                        "chunk_overlap": 128,
                        "min_sentences_per_chunk": 1,
                    }
                }
            }
        },
        enable_textual_memory=True,
        top_k=top_k
    )

def test_memcube_search_and_chat():
    """
    ğŸ¯ æµ‹è¯•MemCubeçš„æœç´¢å’Œå¯¹è¯åŠŸèƒ½ (Ollamaç‰ˆ)
    """
    
    print("ğŸš€ å¼€å§‹æµ‹è¯•MemCubeæœç´¢å’Œå¯¹è¯åŠŸèƒ½ (Ollamaç‰ˆ)...")
    
    # å¯¼å…¥æ­¥éª¤2çš„å‡½æ•°
    from create_memcube_with_memreader_ollama import create_memcube_with_memreader, load_document_to_memcube
    
    # åˆ›å»ºMemCubeå¹¶åŠ è½½æ–‡æ¡£
    print("\n1ï¸âƒ£ åˆ›å»ºMemCubeå¹¶åŠ è½½æ–‡æ¡£...")
    mem_cube = create_memcube_with_memreader()
    # åŠ è½½æ–‡æ¡£
    import os
    current_dir = os.path.dirname(os.path.abspath(__file__))
    doc_path = os.path.join(current_dir, "company_handbook.txt")
    load_document_to_memcube(mem_cube, doc_path)
    
    # åˆ›å»ºMOSé…ç½®
    print("\n2ï¸âƒ£ åˆ›å»ºMOSé…ç½®...")
    mos_config = create_mos_config()
    
    # åˆ›å»ºMOSå®ä¾‹å¹¶æ³¨å†ŒMemCube
    print("3ï¸âƒ£ åˆ›å»ºMOSå®ä¾‹å¹¶æ³¨å†ŒMemCube...")
    mos = MOS(mos_config)
    mos.register_mem_cube(mem_cube, mem_cube_id="handbook")
    
    print("âœ… MOSå®ä¾‹åˆ›å»ºæˆåŠŸï¼")
    print(f"  ğŸ“Š ç”¨æˆ·ID: {mos.user_id}")
    print(f"  ğŸ“Š ä¼šè¯ID: {mos.session_id}")
    print(f"  ğŸ“Š æ³¨å†Œçš„MemCube: {list(mos.mem_cubes.keys())}")
    print(f"  ğŸ¯ é…ç½®æ¨¡å¼: OLLAMA")
    print(f"  ğŸ¤– èŠå¤©æ¨¡å‹: {os.getenv('OLLAMA_CHAT_MODEL')} (Ollama)")
    print(f"  ğŸ” åµŒå…¥æ¨¡å‹: {os.getenv('OLLAMA_EMBED_MODEL')} (Ollama)")
    
    # æµ‹è¯•æœç´¢åŠŸèƒ½
    print("\nğŸ” æµ‹è¯•æœç´¢åŠŸèƒ½...")
    test_queries = [
        "å…¬å¸çš„å·¥ä½œæ—¶é—´æ˜¯ä»€ä¹ˆï¼Ÿ",
        "å¹´å‡æœ‰å¤šå°‘å¤©ï¼Ÿ",
        "æœ‰ä»€ä¹ˆç¦åˆ©å¾…é‡ï¼Ÿ",
        "å¦‚ä½•è”ç³»HRéƒ¨é—¨ï¼Ÿ"
    ]
    
    for query in test_queries:
        print(f"\nâ“ æŸ¥è¯¢: {query}")
        
        # ä½¿ç”¨MOSæœç´¢
        search_results = mos.search(query, top_k=2)
        
        if search_results and search_results.get("text_mem"):
            print(f"ğŸ“‹ æ‰¾åˆ° {len(search_results['text_mem'])} ä¸ªç›¸å…³ç»“æœ:")
            for cube_result in search_results['text_mem']:
                cube_id = cube_result['cube_id']
                memories = cube_result['memories']
                print(f"  ğŸ“¦ MemCube: {cube_id}")
                for i, memory in enumerate(memories[:2], 1):  # åªæ˜¾ç¤ºå‰2ä¸ªç»“æœ
                    print(f"    {i}. {memory.memory[:100]}...")
        else:
            print("ğŸ˜“ æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")
    
    # æµ‹è¯•å¯¹è¯åŠŸèƒ½
    print("\nğŸ’¬ æµ‹è¯•å¯¹è¯åŠŸèƒ½...")
    chat_questions = [
        "å…¬å¸çš„å·¥ä½œæ—¶é—´å®‰æ’æ˜¯æ€æ ·çš„ï¼Ÿ",
        "å‘˜å·¥å¯ä»¥äº«å—å“ªäº›ç¦åˆ©ï¼Ÿ",
        "å¦‚ä½•è”ç³»ITæ”¯æŒéƒ¨é—¨ï¼Ÿ"
    ]
    
    for question in chat_questions:
        print(f"\nğŸ‘¤ é—®é¢˜: {question}")
        
        try:
            response = mos.chat(question)
            print(f"ğŸ¤– å›ç­”: {response}")
        except Exception as e:
            print(f"âŒ å¯¹è¯å¤±è´¥: {e}")
    
    print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
    return mos

if __name__ == "__main__":
    test_memcube_search_and_chat() 