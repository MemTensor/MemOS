import json
from typing import Dict, List, Any

import random
import json
from typing import Dict, List, Any, Set, Tuple
import math

from memos.memories.activation.item import KVCacheItem
from memos.log import get_logger

logger = get_logger(__name__)


def extract_node_name(memory: str) -> str:
    """ä»memoryä¸­æå–å‰ä¸¤ä¸ªè¯ä½œä¸ºnode_name"""
    if not memory:
        return ""
    
    words = [word.strip() for word in memory.split() if word.strip()]
    
    if len(words) >= 2:
        return " ".join(words[:2])
    elif len(words) == 1:
        return words[0]
    else:
        return ""

def analyze_tree_structure_enhanced(nodes: List[Dict], edges: List[Dict]) -> Dict:
    """å¢å¼ºçš„æ ‘ç»“æ„åˆ†æï¼Œé‡ç‚¹å…³æ³¨åˆ†æ”¯åº¦å’Œå¶å­åˆ†å¸ƒ"""
    # æ„å»ºé‚»æ¥è¡¨
    adj_list = {}
    reverse_adj = {}
    for edge in edges:
        source, target = edge['source'], edge['target']
        adj_list.setdefault(source, []).append(target)
        reverse_adj.setdefault(target, []).append(source)
    
    # æ‰¾åˆ°æ‰€æœ‰èŠ‚ç‚¹å’Œæ ¹èŠ‚ç‚¹
    all_nodes = {node['id'] for node in nodes}
    target_nodes = {edge['target'] for edge in edges}
    root_nodes = all_nodes - target_nodes
    
    subtree_analysis = {}
    
    def analyze_subtree_enhanced(root_id: str) -> Dict:
        """å¢å¼ºçš„å­æ ‘åˆ†æï¼Œé‡ç‚¹è¯„ä¼°åˆ†æ”¯åº¦å’Œç»“æ„è´¨é‡"""
        visited = set()
        max_depth = 0
        leaf_count = 0
        total_nodes = 0
        branch_nodes = 0  # æœ‰å¤šä¸ªå­èŠ‚ç‚¹çš„åˆ†æ”¯èŠ‚ç‚¹æ•°
        chain_length = 0  # æœ€é•¿å•é“¾é•¿åº¦
        width_per_level = {}  # æ¯å±‚çš„å®½åº¦
        
        def dfs(node_id: str, depth: int, chain_len: int):
            nonlocal max_depth, leaf_count, total_nodes, branch_nodes, chain_length
            
            if node_id in visited:
                return
            
            visited.add(node_id)
            total_nodes += 1
            max_depth = max(max_depth, depth)
            chain_length = max(chain_length, chain_len)
            
            # è®°å½•æ¯å±‚çš„èŠ‚ç‚¹æ•°
            width_per_level[depth] = width_per_level.get(depth, 0) + 1
            
            children = adj_list.get(node_id, [])
            
            if not children:  # å¶å­èŠ‚ç‚¹
                leaf_count += 1
            elif len(children) > 1:  # åˆ†æ”¯èŠ‚ç‚¹
                branch_nodes += 1
                # é‡ç½®å•é“¾é•¿åº¦ï¼Œå› ä¸ºé‡åˆ°äº†åˆ†æ”¯
                for child in children:
                    dfs(child, depth + 1, 0)
            else:  # å•å­èŠ‚ç‚¹ï¼ˆé“¾å¼ç»“æ„ï¼‰
                for child in children:
                    dfs(child, depth + 1, chain_len + 1)
        
        dfs(root_id, 0, 0)
        
        # è®¡ç®—ç»“æ„è´¨é‡æŒ‡æ ‡
        avg_width = sum(width_per_level.values()) / len(width_per_level) if width_per_level else 0
        max_width = max(width_per_level.values()) if width_per_level else 0
        
        # è®¡ç®—åˆ†æ”¯å¯†åº¦ï¼šåˆ†æ”¯èŠ‚ç‚¹å æ€»èŠ‚ç‚¹çš„æ¯”ä¾‹
        branch_density = branch_nodes / total_nodes if total_nodes > 0 else 0
        
        # è®¡ç®—æ·±åº¦å¹¿åº¦æ¯”ï¼šç†æƒ³çš„æ ‘åº”è¯¥æœ‰é€‚ä¸­çš„æ·±åº¦å’Œè¾ƒå¥½çš„å¹¿åº¦
        depth_width_ratio = max_depth / max_width if max_width > 0 else max_depth
        
        quality_score = calculate_enhanced_quality(
            max_depth, leaf_count, total_nodes, branch_nodes, 
            chain_length, branch_density, depth_width_ratio, max_width
        )
        
        return {
            'root_id': root_id,
            'max_depth': max_depth,
            'leaf_count': leaf_count,
            'total_nodes': total_nodes,
            'branch_nodes': branch_nodes,
            'max_chain_length': chain_length,
            'branch_density': branch_density,
            'max_width': max_width,
            'avg_width': avg_width,
            'depth_width_ratio': depth_width_ratio,
            'nodes_in_subtree': list(visited),
            'quality_score': quality_score,
            'width_per_level': width_per_level
        }
    
    for root_id in root_nodes:
        subtree_analysis[root_id] = analyze_subtree_enhanced(root_id)
    
    return subtree_analysis

def calculate_enhanced_quality(max_depth: int, leaf_count: int, total_nodes: int, 
                             branch_nodes: int, max_chain_length: int, 
                             branch_density: float, depth_width_ratio: float, max_width: int) -> float:
    """å¢å¼ºçš„è´¨é‡è®¡ç®—ï¼Œä¼˜å…ˆè€ƒè™‘åˆ†æ”¯åº¦å’Œå¶å­åˆ†å¸ƒ"""
    
    if total_nodes <= 1:
        return 0.1
    
    # 1. åˆ†æ”¯è´¨é‡åˆ†æ•° (æƒé‡: 35%)
    # åˆ†æ”¯èŠ‚ç‚¹æ•°é‡åˆ†æ•°
    branch_count_score = min(branch_nodes * 3, 15)  # æ¯ä¸ªåˆ†æ”¯èŠ‚ç‚¹3åˆ†ï¼Œæœ€é«˜15åˆ†
    
    # åˆ†æ”¯å¯†åº¦åˆ†æ•°ï¼šç†æƒ³å¯†åº¦åœ¨20%-60%ä¹‹é—´
    if 0.2 <= branch_density <= 0.6:
        branch_density_score = 10
    elif branch_density > 0.6:
        branch_density_score = max(5, 10 - (branch_density - 0.6) * 20)
    else:
        branch_density_score = branch_density * 25  # 0-20%çº¿æ€§å¢é•¿
    
    branch_score = (branch_count_score + branch_density_score) * 0.35
    
    # 2. å¶å­è´¨é‡åˆ†æ•° (æƒé‡: 25%)
    # å¶å­æ•°é‡åˆ†æ•°
    leaf_count_score = min(leaf_count * 2, 20)
    
    # å¶å­åˆ†å¸ƒåˆ†æ•°ï¼šå¶å­å æ€»èŠ‚ç‚¹çš„ç†æƒ³æ¯”ä¾‹30%-70%
    leaf_ratio = leaf_count / total_nodes
    if 0.3 <= leaf_ratio <= 0.7:
        leaf_ratio_score = 10
    elif leaf_ratio > 0.7:
        leaf_ratio_score = max(3, 10 - (leaf_ratio - 0.7) * 20)
    else:
        leaf_ratio_score = leaf_ratio * 20  # 0-30%çº¿æ€§å¢é•¿
    
    leaf_score = (leaf_count_score + leaf_ratio_score) * 0.25
    
    # 3. ç»“æ„å¹³è¡¡åˆ†æ•° (æƒé‡: 25%)
    # æ·±åº¦åˆ†æ•°ï¼šé€‚ä¸­æ·±åº¦æœ€å¥½ï¼ˆ3-8å±‚ï¼‰
    if 3 <= max_depth <= 8:
        depth_score = 15
    elif max_depth < 3:
        depth_score = max_depth * 3  # 1-2å±‚ç»™è¾ƒä½åˆ†
    else:
        depth_score = max(5, 15 - (max_depth - 8) * 1.5)  # è¶…è¿‡8å±‚é€æ¸å‡åˆ†
    
    # å®½åº¦åˆ†æ•°ï¼šæœ€å¤§å®½åº¦è¶Šå¤§è¶Šå¥½ï¼Œä½†æœ‰ä¸Šé™
    width_score = min(max_width * 1.5, 15)
    
    # æ·±åº¦å®½åº¦æ¯”æƒ©ç½šï¼šæ¯”å€¼è¿‡å¤§è¯´æ˜æ ‘å¤ª"ç»†é•¿"
    if depth_width_ratio > 3:
        ratio_penalty = (depth_width_ratio - 3) * 2
        structure_score = max(0, (depth_score + width_score - ratio_penalty)) * 0.25
    else:
        structure_score = (depth_score + width_score) * 0.25
    
    # 4. é“¾å¼ç»“æ„æƒ©ç½š (æƒé‡: 15%)
    # æœ€é•¿å•é“¾é•¿åº¦æƒ©ç½šï¼šå•é“¾è¿‡é•¿ä¸¥é‡å½±å“å±•ç¤ºæ•ˆæœ
    if max_chain_length <= 2:
        chain_penalty_score = 10
    elif max_chain_length <= 5:
        chain_penalty_score = 8 - (max_chain_length - 2)
    else:
        chain_penalty_score = max(0, 3 - (max_chain_length - 5) * 0.5)
    
    chain_score = chain_penalty_score * 0.15
    
    # 5. ç»¼åˆè®¡ç®—
    total_score = branch_score + leaf_score + structure_score + chain_score
    
    # ç‰¹æ®Šæƒ…å†µä¸¥é‡æƒ©ç½š
    if max_chain_length > total_nodes * 0.8:  # å¦‚æœ80%ä»¥ä¸Šéƒ½æ˜¯å•é“¾
        total_score *= 0.3
    elif branch_density < 0.1 and total_nodes > 5:  # å‡ ä¹æ²¡æœ‰åˆ†æ”¯çš„å¤§æ ‘
        total_score *= 0.5
    
    return total_score

def sample_nodes_with_type_balance(nodes: List[Dict], edges: List[Dict], 
                                 target_count: int = 150,
                                 type_ratios: Dict[str, float] = None) -> Tuple[List[Dict], List[Dict]]:
    """
    æ ¹æ®ç±»å‹æ¯”ä¾‹å’Œæ ‘è´¨é‡è¿›è¡Œå¹³è¡¡é‡‡æ ·
    
    Args:
        nodes: èŠ‚ç‚¹åˆ—è¡¨
        edges: è¾¹åˆ—è¡¨
        target_count: ç›®æ ‡èŠ‚ç‚¹æ•°
        type_ratios: å„ç±»å‹æœŸæœ›å æ¯”ï¼Œå¦‚ {'WorkingMemory': 0.15, 'EpisodicMemory': 0.30, ...}
    """
    if len(nodes) <= target_count:
        return nodes, edges
    
    # é»˜è®¤ç±»å‹æ¯”ä¾‹é…ç½®
    if type_ratios is None:
        type_ratios = {
            'WorkingMemory': 0.10,      # 10%
            'EpisodicMemory': 0.25,     # 25%
            'SemanticMemory': 0.25,     # 25%
            'ProceduralMemory': 0.20,   # 20%
            'EmotionalMemory': 0.15,    # 15%
            'MetaMemory': 0.05          # 5%
        }
    
    print(f"å¼€å§‹ç±»å‹å¹³è¡¡é‡‡æ ·ï¼ŒåŸå§‹èŠ‚ç‚¹æ•°: {len(nodes)}, ç›®æ ‡èŠ‚ç‚¹æ•°: {target_count}")
    print(f"ç›®æ ‡ç±»å‹æ¯”ä¾‹: {type_ratios}")
    
    # åˆ†æå½“å‰èŠ‚ç‚¹çš„ç±»å‹åˆ†å¸ƒ
    current_type_counts = {}
    nodes_by_type = {}
    
    for node in nodes:
        memory_type = node.get('metadata', {}).get('memory_type', 'Unknown')
        current_type_counts[memory_type] = current_type_counts.get(memory_type, 0) + 1
        if memory_type not in nodes_by_type:
            nodes_by_type[memory_type] = []
        nodes_by_type[memory_type].append(node)
    
    print(f"å½“å‰ç±»å‹åˆ†å¸ƒ: {current_type_counts}")
    
    # è®¡ç®—æ¯ä¸ªç±»å‹çš„ç›®æ ‡èŠ‚ç‚¹æ•°
    type_targets = {}
    remaining_target = target_count
    
    for memory_type, ratio in type_ratios.items():
        if memory_type in nodes_by_type:
            target_for_type = int(target_count * ratio)
            # ç¡®ä¿ä¸è¶…è¿‡è¯¥ç±»å‹çš„å®é™…èŠ‚ç‚¹æ•°
            target_for_type = min(target_for_type, len(nodes_by_type[memory_type]))
            type_targets[memory_type] = target_for_type
            remaining_target -= target_for_type
    
    # å¤„ç†æœªåœ¨æ¯”ä¾‹é…ç½®ä¸­çš„ç±»å‹
    other_types = set(nodes_by_type.keys()) - set(type_ratios.keys())
    if other_types and remaining_target > 0:
        per_other_type = max(1, remaining_target // len(other_types))
        for memory_type in other_types:
            allocation = min(per_other_type, len(nodes_by_type[memory_type]))
            type_targets[memory_type] = allocation
            remaining_target -= allocation
    
    # å¦‚æœè¿˜æœ‰å‰©ä½™ï¼ŒæŒ‰æ¯”ä¾‹åˆ†é…ç»™ä¸»è¦ç±»å‹
    if remaining_target > 0:
        main_types = [t for t in type_ratios.keys() if t in nodes_by_type]
        if main_types:
            extra_per_type = remaining_target // len(main_types)
            for memory_type in main_types:
                additional = min(extra_per_type, 
                               len(nodes_by_type[memory_type]) - type_targets.get(memory_type, 0))
                type_targets[memory_type] = type_targets.get(memory_type, 0) + additional
    
    print(f"å„ç±»å‹ç›®æ ‡èŠ‚ç‚¹æ•°: {type_targets}")
    
    # å¯¹æ¯ä¸ªç±»å‹è¿›è¡Œå­æ ‘è´¨é‡é‡‡æ ·
    selected_nodes = []
    
    for memory_type, target_for_type in type_targets.items():
        if target_for_type <= 0 or memory_type not in nodes_by_type:
            continue
        
        type_nodes = nodes_by_type[memory_type]
        print(f"\n--- å¤„ç† {memory_type} ç±»å‹: {len(type_nodes)} -> {target_for_type} ---")
        
        if len(type_nodes) <= target_for_type:
            selected_nodes.extend(type_nodes)
            print(f"  å…¨éƒ¨é€‰æ‹©: {len(type_nodes)} ä¸ªèŠ‚ç‚¹")
        else:
            # ä½¿ç”¨å¢å¼ºçš„å­æ ‘è´¨é‡é‡‡æ ·
            type_selected = sample_by_enhanced_subtree_quality(
                type_nodes, edges, target_for_type
            )
            selected_nodes.extend(type_selected)
            print(f"  é‡‡æ ·é€‰æ‹©: {len(type_selected)} ä¸ªèŠ‚ç‚¹")
    
    # è¿‡æ»¤è¾¹
    selected_node_ids = {node['id'] for node in selected_nodes}
    filtered_edges = [edge for edge in edges 
                     if edge['source'] in selected_node_ids and edge['target'] in selected_node_ids]
    
    print(f"\næœ€ç»ˆé€‰æ‹©èŠ‚ç‚¹æ•°: {len(selected_nodes)}")
    print(f"æœ€ç»ˆè¾¹æ•°: {len(filtered_edges)}")
    
    # éªŒè¯æœ€ç»ˆç±»å‹åˆ†å¸ƒ
    final_type_counts = {}
    for node in selected_nodes:
        memory_type = node.get('metadata', {}).get('memory_type', 'Unknown')
        final_type_counts[memory_type] = final_type_counts.get(memory_type, 0) + 1
    
    print(f"æœ€ç»ˆç±»å‹åˆ†å¸ƒ: {final_type_counts}")
    for memory_type, count in final_type_counts.items():
        percentage = count / len(selected_nodes) * 100
        target_percentage = type_ratios.get(memory_type, 0) * 100
        print(f"  {memory_type}: {count} ä¸ª ({percentage:.1f}%, ç›®æ ‡: {target_percentage:.1f}%)")
    
    return selected_nodes, filtered_edges

def sample_by_enhanced_subtree_quality(nodes: List[Dict], edges: List[Dict], target_count: int) -> List[Dict]:
    """ä½¿ç”¨å¢å¼ºçš„å­æ ‘è´¨é‡è¿›è¡Œé‡‡æ ·"""
    if len(nodes) <= target_count:
        return nodes
    
    # åˆ†æå­æ ‘ç»“æ„
    subtree_analysis = analyze_tree_structure_enhanced(nodes, edges)
    
    if not subtree_analysis:
        # å¦‚æœæ²¡æœ‰å­æ ‘ç»“æ„ï¼ŒæŒ‰èŠ‚ç‚¹é‡è¦æ€§é‡‡æ ·
        return sample_nodes_by_importance(nodes, edges, target_count)
    
    # æŒ‰è´¨é‡åˆ†æ•°æ’åºå­æ ‘
    sorted_subtrees = sorted(subtree_analysis.items(), 
                           key=lambda x: x[1]['quality_score'], reverse=True)
    
    print(f"  å­æ ‘è´¨é‡æ’åº:")
    for i, (root_id, analysis) in enumerate(sorted_subtrees[:5]):
        print(f"    #{i+1} æ ¹èŠ‚ç‚¹ {root_id}: è´¨é‡={analysis['quality_score']:.2f}, "
              f"æ·±åº¦={analysis['max_depth']}, åˆ†æ”¯={analysis['branch_nodes']}, "
              f"å¶å­={analysis['leaf_count']}, æœ€å¤§å®½åº¦={analysis['max_width']}")
    
    # è´ªå¿ƒé€‰æ‹©é«˜è´¨é‡å­æ ‘
    selected_nodes = []
    selected_node_ids = set()
    
    for root_id, analysis in sorted_subtrees:
        subtree_nodes = analysis['nodes_in_subtree']
        new_nodes = [node_id for node_id in subtree_nodes if node_id not in selected_node_ids]
        
        if not new_nodes:
            continue
        
        remaining_quota = target_count - len(selected_nodes)
        
        if len(new_nodes) <= remaining_quota:
            # æ•´ä¸ªå­æ ‘éƒ½èƒ½åŠ å…¥
            for node_id in new_nodes:
                node = next((n for n in nodes if n['id'] == node_id), None)
                if node:
                    selected_nodes.append(node)
                    selected_node_ids.add(node_id)
            print(f"    é€‰æ‹©æ•´ä¸ªå­æ ‘ {root_id}: +{len(new_nodes)} èŠ‚ç‚¹")
        else:
            # å­æ ‘å¤ªå¤§ï¼Œéœ€è¦éƒ¨åˆ†é€‰æ‹©
            if analysis['quality_score'] > 5:  # åªå¯¹é«˜è´¨é‡å­æ ‘è¿›è¡Œéƒ¨åˆ†é€‰æ‹©
                subtree_node_objects = [n for n in nodes if n['id'] in new_nodes]
                partial_selection = select_best_nodes_from_subtree(
                    subtree_node_objects, edges, remaining_quota, root_id
                )
                
                selected_nodes.extend(partial_selection)
                for node in partial_selection:
                    selected_node_ids.add(node['id'])
                print(f"    éƒ¨åˆ†é€‰æ‹©å­æ ‘ {root_id}: +{len(partial_selection)} èŠ‚ç‚¹")
        
        if len(selected_nodes) >= target_count:
            break
    
    # å¦‚æœè¿˜æ²¡è¾¾åˆ°ç›®æ ‡æ•°é‡ï¼Œè¡¥å……å‰©ä½™èŠ‚ç‚¹
    if len(selected_nodes) < target_count:
        remaining_nodes = [n for n in nodes if n['id'] not in selected_node_ids]
        remaining_count = target_count - len(selected_nodes)
        additional = sample_nodes_by_importance(remaining_nodes, edges, remaining_count)
        selected_nodes.extend(additional)
        print(f"    è¡¥å……é€‰æ‹©: +{len(additional)} èŠ‚ç‚¹")
    
    return selected_nodes

def select_best_nodes_from_subtree(subtree_nodes: List[Dict], edges: List[Dict], 
                                 max_count: int, root_id: str) -> List[Dict]:
    """ä»å­æ ‘ä¸­é€‰æ‹©æœ€é‡è¦çš„èŠ‚ç‚¹ï¼Œä¼˜å…ˆä¿æŒåˆ†æ”¯ç»“æ„"""
    if len(subtree_nodes) <= max_count:
        return subtree_nodes
    
    # æ„å»ºå­æ ‘å†…éƒ¨çš„è¿æ¥å…³ç³»
    subtree_node_ids = {node['id'] for node in subtree_nodes}
    subtree_edges = [edge for edge in edges 
                    if edge['source'] in subtree_node_ids and edge['target'] in subtree_node_ids]
    
    # è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„é‡è¦æ€§åˆ†æ•°
    node_scores = []
    
    for node in subtree_nodes:
        node_id = node['id']
        
        # å‡ºåº¦å’Œå…¥åº¦
        out_degree = sum(1 for edge in subtree_edges if edge['source'] == node_id)
        in_degree = sum(1 for edge in subtree_edges if edge['target'] == node_id)
        
        # å†…å®¹é•¿åº¦åˆ†æ•°
        content_score = min(len(node.get('memory', '')), 300) / 15
        
        # åˆ†æ”¯èŠ‚ç‚¹é¢å¤–åŠ åˆ†
        branch_bonus = out_degree * 8 if out_degree > 1 else 0
        
        # æ ¹èŠ‚ç‚¹é¢å¤–åŠ åˆ†
        root_bonus = 15 if node_id == root_id else 0
        
        # è¿æ¥é‡è¦æ€§
        connection_score = (out_degree + in_degree) * 3
        
        # å¶å­èŠ‚ç‚¹é€‚åº¦åŠ åˆ†ï¼ˆä¿è¯ä¸€å®šçš„å¶å­èŠ‚ç‚¹ï¼‰
        leaf_bonus = 5 if out_degree == 0 and in_degree > 0 else 0
        
        total_score = content_score + connection_score + branch_bonus + root_bonus + leaf_bonus
        node_scores.append((node, total_score))
    
    # æŒ‰åˆ†æ•°æ’åºå¹¶é€‰æ‹©
    node_scores.sort(key=lambda x: x[1], reverse=True)
    selected = [node for node, _ in node_scores[:max_count]]
    
    return selected

def sample_nodes_by_importance(nodes: List[Dict], edges: List[Dict], target_count: int) -> List[Dict]:
    """æŒ‰èŠ‚ç‚¹é‡è¦æ€§é‡‡æ ·ï¼ˆç”¨äºæ— æ ‘ç»“æ„çš„æƒ…å†µï¼‰"""
    if len(nodes) <= target_count:
        return nodes
    
    node_scores = []
    
    for node in nodes:
        node_id = node['id']
        out_degree = sum(1 for edge in edges if edge['source'] == node_id)
        in_degree = sum(1 for edge in edges if edge['target'] == node_id)
        content_score = min(len(node.get('memory', '')), 200) / 10
        connection_score = (out_degree + in_degree) * 5
        random_score = random.random() * 10
        
        total_score = content_score + connection_score + random_score
        node_scores.append((node, total_score))
    
    node_scores.sort(key=lambda x: x[1], reverse=True)
    return [node for node, _ in node_scores[:target_count]]

# ä¿®æ”¹ä¸»å‡½æ•°ä»¥ä½¿ç”¨æ–°çš„é‡‡æ ·ç­–ç•¥
def convert_graph_to_tree_forworkmem(json_data: Dict[str, Any], 
                                 target_node_count: int = 150,
                                 type_ratios: Dict[str, float] = None) -> Dict[str, Any]:
    """
    å¢å¼ºç‰ˆå›¾è½¬æ ‘å‡½æ•°ï¼Œä¼˜å…ˆè€ƒè™‘åˆ†æ”¯åº¦å’Œç±»å‹å¹³è¡¡
    """
    original_nodes = json_data.get('nodes', [])
    original_edges = json_data.get('edges', [])
    
    print(f"åŸå§‹èŠ‚ç‚¹æ•°é‡: {len(original_nodes)}")
    print(f"ç›®æ ‡èŠ‚ç‚¹æ•°é‡: {target_node_count}")
    filter_original_edges = []
    for original_edge in original_edges:
        if original_edge["type"] == "PARENT":
            filter_original_edges.append(original_edge)
    original_edges = filter_original_edges
    # ä½¿ç”¨å¢å¼ºçš„ç±»å‹å¹³è¡¡é‡‡æ ·
    if len(original_nodes) > target_node_count:
        nodes, edges = sample_nodes_with_type_balance(
            original_nodes, original_edges, target_node_count, type_ratios
        )
    else:
        nodes, edges = original_nodes, original_edges
    
    # æ„å»ºæ ‘ç»“æ„çš„å…¶ä½™éƒ¨åˆ†ä¿æŒä¸å˜...
    # [è¿™é‡Œæ˜¯åŸæ¥çš„æ ‘æ„å»ºä»£ç ]
    
    # åˆ›å»ºèŠ‚ç‚¹æ˜ å°„è¡¨
    node_map = {}
    for node in nodes:
        memory = node.get('memory', '')
        node_map[node['id']] = {
            'id': node['id'],
            'value': memory,
            "frequency": random.randint(1, 100),
            'node_name': extract_node_name(memory),
            'memory_type': node.get('metadata', {}).get('memory_type', 'Unknown'),
            'children': []
        }
    
    # æ„å»ºçˆ¶å­å…³ç³»æ˜ å°„
    children_map = {}
    parent_map = {}
    
    for edge in edges:
        source = edge['source']
        target = edge['target']
        if source not in children_map:
            children_map[source] = []
        children_map[source].append(target)
        parent_map[target] = source
    
    # æ‰¾åˆ°æ ¹èŠ‚ç‚¹
    all_node_ids = set(node_map.keys())
    children_node_ids = set(parent_map.keys())
    root_node_ids = all_node_ids - children_node_ids
    
    # åˆ†ç¦»WorkingMemoryå’Œå…¶ä»–æ ¹èŠ‚ç‚¹
    working_memory_roots = []
    other_roots = []
    
    for root_id in root_node_ids:
        if node_map[root_id]['memory_type'] == 'WorkingMemory':
            working_memory_roots.append(root_id)
        else:
            other_roots.append(root_id)
    
    def build_tree(node_id: str) -> Dict[str, Any]:
        """é€’å½’æ„å»ºæ ‘ç»“æ„"""
        if node_id not in node_map:
            return None
            
        children_ids = children_map.get(node_id, [])
        children = []
        for child_id in children_ids:
            child_tree = build_tree(child_id)
            if child_tree:
                children.append(child_tree)
        
        node = {
            'id': node_id,
            'node_name': node_map[node_id]['node_name'],
            'value': node_map[node_id]['value'],
            'memory_type': node_map[node_id]['memory_type'],
            'frequency': node_map[node_id]['frequency']
        }
        
        if children:
            node['children'] = children
        
        return node
    
    # æ„å»ºæ ¹æ ‘åˆ—è¡¨
    root_trees = []
    for root_id in other_roots:
        tree = build_tree(root_id)
        if tree:
            root_trees.append(tree)
    
    # å¤„ç†WorkingMemory
    if working_memory_roots:
        working_memory_children = []
        for wm_root_id in working_memory_roots:
            tree = build_tree(wm_root_id)
            if tree:
                working_memory_children.append(tree)
        
        working_memory_node = {
            'id': 'WorkingMemory',
            'node_name': 'WorkingMemory',
            'value': 'WorkingMemory',
            'memory_type': 'WorkingMemory',
            'children': working_memory_children,
            'frequency': 0
        }
        
        root_trees.append(working_memory_node)
    
    # åˆ›å»ºæ€»æ ¹èŠ‚ç‚¹
    result = {
        'id': 'root',
        'node_name': 'root',
        'value': 'root',
        'memory_type': 'Root',
        'children': root_trees,
        'frequency': 0
    }
    
    return result

def print_tree_structure(node: Dict[str, Any], level: int = 0, max_level: int = 5):
    """æ‰“å°æ ‘ç»“æ„çš„å‰å‡ å±‚ï¼Œä¾¿äºæŸ¥çœ‹"""
    if level > max_level:
        return
        
    indent = "  " * level
    node_id = node.get('id', 'unknown')
    node_name = node.get('node_name', '')
    node_value = node.get('value', '')
    memory_type = node.get('memory_type', 'Unknown')
    
    # æ ¹æ®æ˜¯å¦æœ‰childrenåˆ¤æ–­æ˜¾ç¤ºæ–¹å¼
    children = node.get('children', [])
    if children:
        # ä¸­é—´èŠ‚ç‚¹ï¼Œæ˜¾ç¤ºåç§°ã€ç±»å‹å’Œå­èŠ‚ç‚¹æ•°é‡
        print(f"{indent}- {node_name} [{memory_type}] ({len(children)} children)")
        print(f"{indent}  ID: {node_id}")
        if len(node_value) > 80:
            display_value = node_value[:80] + "..."
        else:
            display_value = node_value
        print(f"{indent}  Value: {display_value}")
        
        if level < max_level:
            for child in children:
                print_tree_structure(child, level + 1, max_level)
        elif level == max_level:
            print(f"{indent}  ... (å±•å¼€è¢«é™åˆ¶)")
    else:
        # å¶å­èŠ‚ç‚¹ï¼Œæ˜¾ç¤ºåç§°ã€ç±»å‹å’Œvalue
        if len(node_value) > 80:
            display_value = node_value[:80] + "..."
        else:
            display_value = node_value
        print(f"{indent}- {node_name} [{memory_type}]: {display_value}")
        print(f"{indent}  ID: {node_id}")

def analyze_final_tree_quality(tree_data: Dict[str, Any]) -> Dict:
    """åˆ†ææœ€ç»ˆæ ‘çš„è´¨é‡ï¼ŒåŒ…æ‹¬ç±»å‹å¤šæ ·æ€§ã€åˆ†æ”¯ç»“æ„ç­‰"""
    stats = {
        'total_nodes': 0,
        'by_type': {},
        'by_depth': {},
        'max_depth': 0,
        'total_leaves': 0,
        'total_branches': 0,  # æœ‰å¤šä¸ªå­èŠ‚ç‚¹çš„åˆ†æ”¯èŠ‚ç‚¹æ•°
        'subtrees': [],
        'type_diversity': {},
        'structure_quality': {},
        'chain_analysis': {}  # å•é“¾ç»“æ„åˆ†æ
    }
    
    def analyze_subtree(node, depth=0, parent_path="", chain_length=0):
        stats['total_nodes'] += 1
        stats['max_depth'] = max(stats['max_depth'], depth)
        
        # æŒ‰ç±»å‹ç»Ÿè®¡
        memory_type = node.get('memory_type', 'Unknown')
        stats['by_type'][memory_type] = stats['by_type'].get(memory_type, 0) + 1
        
        # æŒ‰æ·±åº¦ç»Ÿè®¡
        stats['by_depth'][depth] = stats['by_depth'].get(depth, 0) + 1
        
        children = node.get('children', [])
        current_path = f"{parent_path}/{node.get('node_name', 'unknown')}" if parent_path else node.get('node_name', 'root')
        
        # åˆ†æèŠ‚ç‚¹ç±»å‹
        if not children:  # å¶å­èŠ‚ç‚¹
            stats['total_leaves'] += 1
            # è®°å½•å•é“¾é•¿åº¦
            if 'max_chain_length' not in stats['chain_analysis']:
                stats['chain_analysis']['max_chain_length'] = 0
            stats['chain_analysis']['max_chain_length'] = max(
                stats['chain_analysis']['max_chain_length'], chain_length
            )
        elif len(children) == 1:  # å•å­èŠ‚ç‚¹ï¼ˆé“¾å¼ï¼‰
            # ç»§ç»­è®¡ç®—é“¾é•¿åº¦
            for child in children:
                analyze_subtree(child, depth + 1, current_path, chain_length + 1)
            return  # æå‰è¿”å›ï¼Œé¿å…é‡å¤å¤„ç†
        else:  # åˆ†æ”¯èŠ‚ç‚¹ï¼ˆå¤šä¸ªå­èŠ‚ç‚¹ï¼‰
            stats['total_branches'] += 1
            # é‡ç½®é“¾é•¿åº¦
            chain_length = 0
        
        # å¦‚æœæ˜¯ä¸»è¦å­æ ‘çš„æ ¹èŠ‚ç‚¹ï¼Œåˆ†æå…¶ç‰¹å¾
        if depth <= 2 and children:  # ä¸»è¦å­æ ‘
            subtree_depth = 0
            subtree_leaves = 0
            subtree_nodes = 0
            subtree_branches = 0
            subtree_types = {}
            subtree_max_width = 0
            width_per_level = {}
            
            def count_subtree(subnode, subdepth):
                nonlocal subtree_depth, subtree_leaves, subtree_nodes, subtree_branches, subtree_max_width
                subtree_nodes += 1
                subtree_depth = max(subtree_depth, subdepth)
                
                # ç»Ÿè®¡å­æ ‘å†…çš„ç±»å‹åˆ†å¸ƒ
                sub_memory_type = subnode.get('memory_type', 'Unknown')
                subtree_types[sub_memory_type] = subtree_types.get(sub_memory_type, 0) + 1
                
                # ç»Ÿè®¡æ¯å±‚å®½åº¦
                width_per_level[subdepth] = width_per_level.get(subdepth, 0) + 1
                subtree_max_width = max(subtree_max_width, width_per_level[subdepth])
                
                subchildren = subnode.get('children', [])
                if not subchildren:
                    subtree_leaves += 1
                elif len(subchildren) > 1:
                    subtree_branches += 1
                
                for child in subchildren:
                    count_subtree(child, subdepth + 1)
            
            count_subtree(node, 0)
            
            # è®¡ç®—å­æ ‘è´¨é‡æŒ‡æ ‡
            branch_density = subtree_branches / subtree_nodes if subtree_nodes > 0 else 0
            leaf_ratio = subtree_leaves / subtree_nodes if subtree_nodes > 0 else 0
            depth_width_ratio = subtree_depth / subtree_max_width if subtree_max_width > 0 else subtree_depth
            
            stats['subtrees'].append({
                'root': node.get('node_name', 'unknown'),
                'type': memory_type,
                'depth': subtree_depth,
                'leaves': subtree_leaves,
                'nodes': subtree_nodes,
                'branches': subtree_branches,
                'branch_density': branch_density,
                'leaf_ratio': leaf_ratio,
                'max_width': subtree_max_width,
                'depth_width_ratio': depth_width_ratio,
                'path': current_path,
                'type_distribution': subtree_types,
                'quality_score': calculate_enhanced_quality(
                    subtree_depth, subtree_leaves, subtree_nodes, subtree_branches,
                    0, branch_density, depth_width_ratio, subtree_max_width
                )
            })
        
        # é€’å½’åˆ†æå­èŠ‚ç‚¹
        for child in children:
            analyze_subtree(child, depth + 1, current_path, 0)  # é‡ç½®é“¾é•¿åº¦
    
    analyze_subtree(tree_data)
    
    # è®¡ç®—æ•´ä½“ç»“æ„è´¨é‡
    if stats['total_nodes'] > 1:
        branch_density = stats['total_branches'] / stats['total_nodes']
        leaf_ratio = stats['total_leaves'] / stats['total_nodes']
        
        # è®¡ç®—å¹³å‡æ¯å±‚å®½åº¦
        total_width = sum(stats['by_depth'].values())
        avg_width = total_width / len(stats['by_depth']) if stats['by_depth'] else 0
        max_width = max(stats['by_depth'].values()) if stats['by_depth'] else 0
        
        stats['structure_quality'] = {
            'branch_density': branch_density,
            'leaf_ratio': leaf_ratio,
            'avg_width': avg_width,
            'max_width': max_width,
            'depth_width_ratio': stats['max_depth'] / max_width if max_width > 0 else stats['max_depth'],
            'is_well_balanced': 0.2 <= branch_density <= 0.6 and 0.3 <= leaf_ratio <= 0.7
        }
    
    # è®¡ç®—ç±»å‹å¤šæ ·æ€§æŒ‡æ ‡
    total_types = len(stats['by_type'])
    if total_types > 1:
        # è®¡ç®—ç±»å‹åˆ†å¸ƒçš„å‡åŒ€åº¦ (é¦™å†œå¤šæ ·æ€§æŒ‡æ•°)
        shannon_diversity = 0
        for count in stats['by_type'].values():
            if count > 0:
                p = count / stats['total_nodes']
                shannon_diversity -= p * math.log2(p)
        
        # å½’ä¸€åŒ–å¤šæ ·æ€§æŒ‡æ•° (0-1ä¹‹é—´)
        max_diversity = math.log2(total_types) if total_types > 1 else 0
        normalized_diversity = shannon_diversity / max_diversity if max_diversity > 0 else 0
        
        stats['type_diversity'] = {
            'total_types': total_types,
            'shannon_diversity': shannon_diversity,
            'normalized_diversity': normalized_diversity,
            'distribution_balance': min(stats['by_type'].values()) / max(stats['by_type'].values()) if max(stats['by_type'].values()) > 0 else 0
        }
    
    # å•é“¾åˆ†æ
    total_single_child_nodes = sum(1 for subtree in stats['subtrees'] 
                                  if subtree.get('branch_density', 0) < 0.1)
    stats['chain_analysis'].update({
        'single_chain_subtrees': total_single_child_nodes,
        'chain_subtree_ratio': total_single_child_nodes / len(stats['subtrees']) if stats['subtrees'] else 0
    })
    
    return stats

def print_tree_analysis(tree_data: Dict[str, Any]):
    """æ‰“å°å¢å¼ºçš„æ ‘åˆ†æç»“æœ"""
    stats = analyze_final_tree_quality(tree_data)
    
    print("\n" + "="*60)
    print("ğŸŒ³ å¢å¼ºæ ‘ç»“æ„è´¨é‡åˆ†ææŠ¥å‘Š")
    print("="*60)
    
    # åŸºç¡€ç»Ÿè®¡
    print(f"\nğŸ“Š åŸºç¡€ç»Ÿè®¡:")
    print(f"  æ€»èŠ‚ç‚¹æ•°: {stats['total_nodes']}")
    print(f"  æœ€å¤§æ·±åº¦: {stats['max_depth']}")
    print(f"  å¶å­èŠ‚ç‚¹æ•°: {stats['total_leaves']} ({stats['total_leaves']/stats['total_nodes']*100:.1f}%)")
    print(f"  åˆ†æ”¯èŠ‚ç‚¹æ•°: {stats['total_branches']} ({stats['total_branches']/stats['total_nodes']*100:.1f}%)")
    
    # ç»“æ„è´¨é‡è¯„ä¼°
    structure = stats.get('structure_quality', {})
    if structure:
        print(f"\nğŸ—ï¸  ç»“æ„è´¨é‡è¯„ä¼°:")
        print(f"  åˆ†æ”¯å¯†åº¦: {structure['branch_density']:.3f} ({'âœ… è‰¯å¥½' if 0.2 <= structure['branch_density'] <= 0.6 else 'âš ï¸  éœ€æ”¹è¿›'})")
        print(f"  å¶å­æ¯”ä¾‹: {structure['leaf_ratio']:.3f} ({'âœ… è‰¯å¥½' if 0.3 <= structure['leaf_ratio'] <= 0.7 else 'âš ï¸  éœ€æ”¹è¿›'})")
        print(f"  æœ€å¤§å®½åº¦: {structure['max_width']}")
        print(f"  æ·±åº¦å®½åº¦æ¯”: {structure['depth_width_ratio']:.2f} ({'âœ… è‰¯å¥½' if structure['depth_width_ratio'] <= 3 else 'âš ï¸  è¿‡ç»†é•¿'})")
        print(f"  æ•´ä½“å¹³è¡¡æ€§: {'âœ… è‰¯å¥½' if structure['is_well_balanced'] else 'âš ï¸  éœ€æ”¹è¿›'}")
    
    # å•é“¾åˆ†æ
    chain_analysis = stats.get('chain_analysis', {})
    if chain_analysis:
        print(f"\nğŸ”— å•é“¾ç»“æ„åˆ†æ:")
        print(f"  æœ€é•¿å•é“¾: {chain_analysis.get('max_chain_length', 0)} å±‚")
        print(f"  å•é“¾å­æ ‘æ•°: {chain_analysis.get('single_chain_subtrees', 0)}")
        print(f"  å•é“¾å­æ ‘æ¯”ä¾‹: {chain_analysis.get('chain_subtree_ratio', 0)*100:.1f}%")
        
        if chain_analysis.get('max_chain_length', 0) > 5:
            print("  âš ï¸  è­¦å‘Š: å­˜åœ¨è¿‡é•¿çš„å•é“¾ç»“æ„ï¼Œå¯èƒ½å½±å“å±•ç¤ºæ•ˆæœ")
        elif chain_analysis.get('chain_subtree_ratio', 0) > 0.3:
            print("  âš ï¸  è­¦å‘Š: å•é“¾å­æ ‘è¿‡å¤šï¼Œå»ºè®®å¢åŠ åˆ†æ”¯ç»“æ„")
        else:
            print("  âœ… å•é“¾ç»“æ„æ§åˆ¶è‰¯å¥½")
    
    # ç±»å‹å¤šæ ·æ€§
    type_div = stats.get('type_diversity', {})
    if type_div:
        print(f"\nğŸ¨ ç±»å‹å¤šæ ·æ€§åˆ†æ:")
        print(f"  ç±»å‹æ€»æ•°: {type_div['total_types']}")
        print(f"  å¤šæ ·æ€§æŒ‡æ•°: {type_div['shannon_diversity']:.3f}")
        print(f"  å½’ä¸€åŒ–å¤šæ ·æ€§: {type_div['normalized_diversity']:.3f}")
        print(f"  åˆ†å¸ƒå¹³è¡¡åº¦: {type_div['distribution_balance']:.3f}")
    
    # ç±»å‹åˆ†å¸ƒ
    print(f"\nğŸ“‹ ç±»å‹åˆ†å¸ƒè¯¦æƒ…:")
    for mem_type, count in sorted(stats['by_type'].items(), key=lambda x: x[1], reverse=True):
        percentage = count / stats['total_nodes'] * 100
        print(f"  {mem_type}: {count} ä¸ªèŠ‚ç‚¹ ({percentage:.1f}%)")
    
    # æ·±åº¦åˆ†å¸ƒ
    print(f"\nğŸ“ æ·±åº¦åˆ†å¸ƒ:")
    for depth in sorted(stats['by_depth'].keys()):
        count = stats['by_depth'][depth]
        print(f"  æ·±åº¦ {depth}: {count} ä¸ªèŠ‚ç‚¹")
    
    # ä¸»è¦å­æ ‘åˆ†æ
    if stats['subtrees']:
        print(f"\nğŸŒ² ä¸»è¦å­æ ‘åˆ†æ (æŒ‰è´¨é‡æ’åº):")
        sorted_subtrees = sorted(stats['subtrees'], key=lambda x: x.get('quality_score', 0), reverse=True)
        for i, subtree in enumerate(sorted_subtrees[:8]):  # æ˜¾ç¤ºå‰8ä¸ª
            quality = subtree.get('quality_score', 0)
            print(f"  #{i+1} {subtree['root']} [{subtree['type']}]:")
            print(f"    è´¨é‡åˆ†æ•°: {quality:.2f}")
            print(f"    ç»“æ„: æ·±åº¦={subtree['depth']}, åˆ†æ”¯={subtree['branches']}, å¶å­={subtree['leaves']}")
            print(f"    å¯†åº¦: åˆ†æ”¯å¯†åº¦={subtree.get('branch_density', 0):.3f}, å¶å­æ¯”ä¾‹={subtree.get('leaf_ratio', 0):.3f}")
            
            if quality > 15:
                print(f"    âœ… é«˜è´¨é‡å­æ ‘")
            elif quality > 8:
                print(f"    ğŸŸ¡ ä¸­ç­‰è´¨é‡å­æ ‘")
            else:
                print(f"    ğŸ”´ ä½è´¨é‡å­æ ‘")
    
    print("\n" + "="*60)


def remove_embedding_recursive(memory_info: dict) -> Any:
    """remove the embedding from the memory info
    Args:
        memory_info: product memory info
    
    Returns:
        Any: product memory info without embedding
    """
    if isinstance(memory_info, dict):
        new_dict = {}
        for key, value in memory_info.items():
            if key != "embedding":
                new_dict[key] = remove_embedding_recursive(value)
        return new_dict
    elif isinstance(memory_info, list):
        return [remove_embedding_recursive(item) for item in memory_info]
    else:
        return memory_info
    
def remove_embedding_from_memory_items(memory_items: list[Any]) -> list[dict]:
    """æ‰¹é‡ç§»é™¤å¤šä¸ª TextualMemoryItem ä¸­çš„ embedding å­—æ®µ"""
    clean_memories = []
    
    for item in memory_items:
        memory_dict = item.model_dump()
        
        # ç§»é™¤ metadata ä¸­çš„ embedding
        if "metadata" in memory_dict and "embedding" in memory_dict["metadata"]:
            del memory_dict["metadata"]["embedding"]
        
        clean_memories.append(memory_dict)
    
    return clean_memories
    
def sort_children_by_memory_type(children: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    sort the children by the memory_type
    Args:
        children: the children of the node
    Returns:
        the sorted children
    """
    if not children:
        return children
    
    def get_sort_key(child):
        memory_type = child.get('memory_type', 'Unknown')
        # ç›´æ¥æŒ‰memory_typeå­—ç¬¦ä¸²æ’åºï¼Œç›¸åŒç±»å‹è‡ªç„¶ä¼šèšé›†åœ¨ä¸€èµ·
        return memory_type
    
    # æŒ‰memory_typeæ’åº
    sorted_children = sorted(children, key=get_sort_key)
    
    return sorted_children


def extract_all_ids_from_tree(tree_node):
    """
    é€’å½’éå†æ ‘çŠ¶ç»“æ„ï¼Œæå–æ‰€æœ‰èŠ‚ç‚¹çš„ID
    
    Args:
        tree_node: æ ‘çš„èŠ‚ç‚¹ï¼ˆå­—å…¸æ ¼å¼ï¼‰
        
    Returns:
        set: åŒ…å«æ‰€æœ‰èŠ‚ç‚¹IDçš„é›†åˆ
    """
    ids = set()
    
    # æ·»åŠ å½“å‰èŠ‚ç‚¹çš„IDï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if 'id' in tree_node:
        ids.add(tree_node['id'])
    
    # é€’å½’å¤„ç†å­èŠ‚ç‚¹
    if 'children' in tree_node and tree_node['children']:
        for child in tree_node['children']:
            ids.update(extract_all_ids_from_tree(child))
    
    return ids

def filter_nodes_by_tree_ids(tree_data, nodes_data):
    """
    æ ¹æ®æ ‘çŠ¶ç»“æ„ä¸­ä½¿ç”¨çš„IDç­›é€‰nodesåˆ—è¡¨
    
    Args:
        tree_data: æ ‘çŠ¶ç»“æ„æ•°æ®ï¼ˆå­—å…¸ï¼‰
        nodes_data: åŒ…å«nodesåˆ—è¡¨çš„æ•°æ®ï¼ˆå­—å…¸ï¼‰
        
    Returns:
        dict: ç­›é€‰åçš„nodesæ•°æ®ï¼Œä¿æŒåŸæœ‰ç»“æ„
    """
    # æå–æ ‘ä¸­æ‰€æœ‰ä½¿ç”¨çš„ID
    used_ids = extract_all_ids_from_tree(tree_data)
    
    # ç­›é€‰nodesåˆ—è¡¨ï¼Œåªä¿ç•™IDåœ¨æ ‘ä¸­ä½¿ç”¨çš„èŠ‚ç‚¹
    filtered_nodes = [
        node for node in nodes_data['nodes'] 
        if node['id'] in used_ids
    ]
    
    # è¿”å›ä¿æŒåŸæœ‰ç»“æ„çš„ç»“æœ
    return {
        'nodes': filtered_nodes
    }


def convert_activation_memory_to_serializable(act_mem_items: List[KVCacheItem]) -> List[Dict[str, Any]]:
    """
    Convert activation memory items to a serializable format.
    
    Args:
        act_mem_items: List of KVCacheItem objects
        
    Returns:
        List of dictionaries with serializable data
    """
    serializable_items = []
    
    for item in act_mem_items:
        # Extract basic information that can be serialized
        serializable_item = {
            "id": item.id,
            "metadata": item.metadata,
            "memory_info": {
                "type": "DynamicCache",
                "key_cache_layers": len(item.memory.key_cache) if item.memory else 0,
                "value_cache_layers": len(item.memory.value_cache) if item.memory else 0,
                "device": str(item.memory.key_cache[0].device) if item.memory and item.memory.key_cache else "unknown",
                "dtype": str(item.memory.key_cache[0].dtype) if item.memory and item.memory.key_cache else "unknown",
            }
        }
        
        # Add tensor shape information if available
        if item.memory and item.memory.key_cache:
            key_shapes = []
            value_shapes = []
            
            for i, key_tensor in enumerate(item.memory.key_cache):
                if key_tensor is not None:
                    key_shapes.append({
                        "layer": i,
                        "shape": list(key_tensor.shape)
                    })
                
                if i < len(item.memory.value_cache) and item.memory.value_cache[i] is not None:
                    value_shapes.append({
                        "layer": i,
                        "shape": list(item.memory.value_cache[i].shape)
                    })
            
            serializable_item["memory_info"]["key_shapes"] = key_shapes
            serializable_item["memory_info"]["value_shapes"] = value_shapes
        
        serializable_items.append(serializable_item)
    
    return serializable_items


def convert_activation_memory_summary(act_mem_items: List[KVCacheItem]) -> Dict[str, Any]:
    """
    Create a summary of activation memory for API responses.
    
    Args:
        act_mem_items: List of KVCacheItem objects
        
    Returns:
        Dictionary with summary information
    """
    if not act_mem_items:
        return {
            "total_items": 0,
            "summary": "No activation memory items found"
        }
    
    total_items = len(act_mem_items)
    total_layers = 0
    total_parameters = 0
    
    for item in act_mem_items:
        if item.memory and item.memory.key_cache:
            total_layers += len(item.memory.key_cache)
            
            # Calculate approximate parameter count
            for key_tensor in item.memory.key_cache:
                if key_tensor is not None:
                    total_parameters += key_tensor.numel()
            
            for value_tensor in item.memory.value_cache:
                if value_tensor is not None:
                    total_parameters += value_tensor.numel()
    
    return {
        "total_items": total_items,
        "total_layers": total_layers,
        "total_parameters": total_parameters,
        "summary": f"Activation memory contains {total_items} items with {total_layers} layers and approximately {total_parameters:,} parameters"
    }